\documentclass[12pt,a4paper]{report}     % font size= 12,paper size= a4, document type= report 
\usepackage{graphics}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{fancybox}		% For formatting of cover page5
\usepackage{amsmath}    	% For  mathematical formulae
\usepackage{amssymb}
\usepackage{setspace}		% For adjusting line spacing 
\usepackage{pdfpages}
\usepackage{hyperref}                     % pacakage for 
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{adjustbox}
% pacakage for including header and footer 
%\usepackage{times}                        % package for font type
\usepackage[left=1in,right=1in,top=1in,bottom=0.8in]{geometry} %
\usepackage{url}
\usepackage{rotating}
\usepackage{array}
\usepackage{enumitem}
%\usepackage{bbding}
\usepackage{amsfonts}

\makeatletter
\def\@makechapterhead#1{%
  \vspace*{5\p@}%
  {\parindent \z@ \raggedright \normalfont
    \ifnum \c@secnumdepth >\m@ne
       \LARGE\bfseries \space \thechapter. \space
    \interlinepenalty\@M
    \LARGE \bfseries #1\par\nobreak
    \vskip 10\p@
  }}
  \makeatother
\begin{document}
\newpage
\pagestyle{plain}
\pagestyle{empty}
\pagestyle{fancy}							%display header, footer
\renewcommand{\headrulewidth}{0pt}
%\pagenumbering{arabic}						%display page numbers in arabic								 %set header to left	

%\fancyfoot[LO]{\textit{P:F-SMR-UG/08/R0}}			%set footer to left
\fancypagestyle{plain}{}

 %\thispagestyle{empty}
	\pagenumbering{gobble}
	\thisfancyput(-0.0in,-10.0in){%
	%\thisfancypage{%
%\setlength{\fboxrule}{1pt}\doublebox}{} 
\setlength{\unitlength}{1in}\framebox(6.7,10.2)}
\begin{center}
      
      \begin{center} {A} \end{center}
      \vspace{0.2 in}
      { PRELIMINARY PROJECT REPORT}
      \vspace{0.2 in}\\
       ON
			\end{center}
	\begin{center}
	    \vspace{0.1 in}
		\textbf{\large  Medical Abstract Segmentation } % Give Your Seminar Title
		\vspace{0.2 in}
	\end{center}
     \vspace{0.2 in}
		\begin{center}
	    SUBMITTED TO THE SAVITRIBAI PHULE PUNE UNIVERSITY, PUNE \\
	    IN PARTIAL FULFILLMENT OF THE REQUIREMENTS\\
	    FOR THE AWARD OF THE DEGREE OF
	\end{center}
	\vspace{0.1 in}
	
	\begin{center}
	   {BACHELOR OF ENGINEERING}\\
	    \begin{small}{ INFORMATION TECHNOLOGY}
\end{small}	\end{center}
	\vspace{0.1 in}
	
	\begin{center}
	   \textbf{BY}
	\end{center}
	\vspace{0.1 in}
	
	\begin{center}
\begin{tabular}{ c c }
    
    Saifuddin Shaikh & SPPU Seat No. \\
    Rishikesh Suryavanshi & SPPU Seat No. \\
    Pranish Warke & SPPU Seat No. \\
\end{tabular}
 
	\end{center}
	\vspace{0.1 in}
	
	\begin{center}
	    {Under the guidance of }\\
	    {\textbf{Dr. Emmanuel M.}}  % Here write Your Seminar Guide Name
	\end{center}

		\vspace{0.075in}

	\begin{center}
	  \begin{figure}[h]
			\centering
			\includegraphics[scale=1.5]{pict_logo.png}
		\end{figure}
		\vspace{0.1cm}
	  \begin{large}\textsc {Department Of Information Technology} \end{large}\\
	  \textsc{Pune Institute of Computer Technology}\\
%	  \textsc{Sr. No 27, Near Trimurti Chowk, Dhankawadi}\\
	  \textsc{Pune - 411 043.}\\
	      \textbf{2023-2024}
	\end{center}

%------------------------------------------------------------------------------
%  Cover ends here
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
%  Certificate starts here
%------------------------------------------------------------------------------
\newpage
\pagestyle{plain}
\pagestyle{empty}
\pagestyle{fancy}							%display header, footer
\renewcommand{\headrulewidth}{0pt}
%\pagenumbering{arabic}						%display page numbers in arabic								 %set header to left	
%\fancyfoot[LO]{\textit{P:F-SMR-UG/08/R0}}			%set footer to left
\fancypagestyle{plain}{}

 %\thispagestyle{empty}
		\pagenumbering{roman}
		
	\thisfancyput(-0.15in,-9.7in){%
	%\thisfancypage{%
%\setlength{\fboxrule}{1pt}\doublebox}{} 
\setlength{\unitlength}{1in}\framebox(6.7,10.2)}
\begin{center}

{ SCTR's
   PUNE INSTITUTE OF COMPUTER TECHNOLOGY \\
   \small{DEPARTMENT OF INFORMATION TECHNOLOGY} \\

}
\vspace{0.10in}

\vspace{0.1in}
\includegraphics[scale=1.5]{pict_logo.png}
\end{center}
\vspace{0.075in}
\begin{center}
\textbf{\underline{C E R T I F I C A T E}}
\vspace{0.08in}
\end{center}
		\noindent
  				\setlength{\baselineskip}{1.1\baselineskip}
	\begin{center}
This is to certify that the preliminary project report entitled  \\
		\textbf{Medical Abstract Segmentation} 
\singlespace
submitted by\\
\begin{center}
\begin{tabular}{ c c }
    
    Saifuddin Shaikh & SPPU Seat No. \\
    Rishikesh Suryavanshi & SPPU Seat No. \\
    Pranish Warke & SPPU Seat No. \\
\end{tabular}
 
	\end{center}
	\end{center}

\onehalfspace
\begin{quote}
is a bonafide work carried out by them under the supervision of \textbf{Dr. Emmanuel M.} and
it is approved for the partial fulfillment of the requirement of Savitribai Phule Pune University for the award of the Degree of Bachelor of Engineering (Information Technology).\\

This project report has not been earlier submitted to any other Institute or University for the award of any degree or diploma.\\
\end{quote}
		\noindent 
		


\begin{quote}
\singlespace
%\\[0.5in]
\textbf{Dr. Emmanuel M.} % include Seminar Guide Name
\hspace{2.2 in} \textbf{Dr. A. S. Ghotkar}\\
Project Guide\hspace{3.2 in}       HOD IT \\\\\\

\textbf{} % include Seminar Guide Name
\hspace{3.7in} \textbf{Dr. S. T. Gandhe}\\
SPPU External Guide\hspace{2.6in}       Principal \\\\\\

Date:       \\ %write date in the form of dd/mm/yyyy format
Place:       %write place as Pune
\\\\


 \end{quote}
\addcontentsline{toc}{section}{Certificate}
%------------------------------------------------------------------------------
%  Certificate ends here
%------------------------------------------------------------------------------

\newpage	
\pagestyle{plain}
%\pagestyle{empty}
\pagestyle{fancy}							%display header, footer
\renewcommand{\headrulewidth}{0pt}
%\pagenumbering{arabic}						%display page numbers in arabic								 %set header to left	
\fancyfoot[LO]{\textit{}}			%set footer to left
\fancypagestyle{plain}{}%start a new page
		\pagestyle{plain}           %dont display header footer and page nos
%\vline
		\begin{center}				%centre align the text
			\begin{LARGE}
	\section*{Acknowledgement}
			\addcontentsline{toc}{section}{Acknowledgement}
				%leave space of 0.5 inches vertically
			\end{LARGE}
		\end{center}
		\begin{normalsize}
%				\begin{quote}
{\setlength{\baselineskip}{1.1\baselineskip}
\noindent %Start acknowledgement from here.
With deep sense of gratitude we would like to thanks all the people who have lit our path with their
kind guidance for our Project Selection, Design and Development. We are very grateful to these
intellectuals, experts, who did their best to help during our completion of project work.
\newline
It is our proud privilege to express deep sense of gratitude to the Principal, Prof. S. T. Gandhe,
SCTR's Pune Institue of Computer Technology, Pune for his comments and kind permission to complete this project. We
remain indebted to Prof. Archana S. Ghotkar, Head of Informattion Technology Department for her timely
suggestion and valuable guidance.
\newline
The special gratitude goes to our Internal Project Guide Dr. Emmanuel Markappa, staff members,
technical staff members of Information Technology Department for his/her technical, timely, excellent
and coercive guidance in completion of this project work. We thanks to all the class colleagues for
their appreciable, encouraging help for completion of our project.








			\vspace{1.8in}
				\begin{flushright} 
\begin{tabular}{ c c }
    Saifuddin Shaikh & SPPU Seat No. \\
    Rishikesh Suryavanshi & SPPU Seat No. \\
    Pranish Warke & SPPU Seat No. \\
\end{tabular}
 \end{flushright}
%				\end{quote}

}
		\end{normalsize}
		

\newpage
% \section*{Sponsorship letter (if any)}
\addcontentsline{toc}{section}{Sponsorship letter}
%-----------------------------------Abstract------------------------------------------
		\newpage					%start a new page
		\pagestyle{plain}           %dont display header footer and display page nos
		\begin{center}				%centre align the text
			\begin{LARGE}
						\section*{ Abstract}
			%\vspace{.15 in}       %leave space of 0.5 inches vertically
			\end{LARGE}
		\end{center}
		\begin{normalsize}
{\setlength{\baselineskip}{1.1\baselineskip}   %set line spacing as 1.5
\noindent % Start writing abstract from here.
Randomized control trials (RCTs) are essential for evaluating the effectiveness of medical interventions, but their results are often buried within lengthy and complex documents. Efficiently extracting and organizing critical information from RCT abstracts can significantly impact evidence-based decision-making and healthcare research. The automated segmentation of medical abstracts is a vital component of medical information retrieval and analysis, significantly impacting clinical decision-making, healthcare research, and knowledge discovery. This paper presents an innovative approach to segmenting abstracts of RCTs through the application of natural language processing (NLP) and neural networks. The practical applications of NLP and neural network-based text segmentation in the context of RCTs are exemplified, ranging from systematic reviews and meta-analyses to the development of clinical guidelines. Case studies are presented to showcase the impact of this technology in improving the accessibility and utilization of RCT results. This paper serves as a valuable resource for researchers, healthcare professionals, and data scientists, offering a glimpse into the future of RCT abstract segmentation. It underscores the pivotal role of NLP and neural networks in unlocking the potential of RCT data, ultimately advancing the field of evidence-based medicine and healthcare decision-making.  \\\\ 
\textbf{Keywords:} % start writing Keywords from here
medical abstract,text segmentation,randomized control trial (RCT),natural language processing(NLP),neural networks\\\\
\par}
		\end{normalsize}
\addcontentsline{toc}{section}{Abstract}
%---------------------------------Abstract ends---------------------------------------
\newpage

\thispagestyle{empty}
\fancyhead{}
\renewcommand{\headrulewidth}{0pt}
%\fancypagestyle{plain}{}%start a new page
%		\thispagestyle{plain} 

\addcontentsline{toc}{section}{Contents}
\tableofcontents	 								% auto generate table of contents
\newpage
{\setlength{\baselineskip}{1.1\baselineskip}        % auto generate list of figures  
\listoffigures
\addcontentsline{toc}{section}{List of Figures}   % add to table of contents
}
\newpage
{\setlength{\baselineskip}{1.1\baselineskip}        % auto generate list of tables   
\listoftables
\addcontentsline{toc}{section}{List of Tables}
}
%---------------------------Abbrevations------------------------------------------------------------
\newpage
		\begin{LARGE}
			\begin{flushleft}
				\section*{\centering{Abbreviations}}
			\end{flushleft}
		\end{LARGE}
		\addcontentsline{toc}{section}{Abbreviations}	
\begin{normalsize}
					\noindent
{\setlength{\baselineskip}{1.1\baselineskip}
\vspace{0.2 in}
\begin{tabular}{lll}
\vspace{0.1 in}
LSTM	&	:	&	Long Short Term Memory	\\
\vspace{0.1 in}
BERT	&	:	&	Bidirectional Encoder Representations from Transformers\\
\vspace{0.1 in}
RCT	&	:	&	Randomised Control Trial 	\\
\vspace{0.1 in}
NLP	&	:	&	Natural Language Processing 	\\
\vspace{0.1 in}
GRU	&	:	&	Gated Recurrent Unit 	\\
\end{tabular}
\par}
\end{normalsize}

%-----------------------------------Chapter 1 Introduction}
\newpage
%\clearpage
\pagestyle{fancy}							%display header, footer
\pagenumbering{arabic}	%display page numbers in arabic
\renewcommand{\headrulewidth}{0.5pt}
\fancyhead[RO]{\textit{ Medical Abstract Segmentation }} %set header to right
\fancyhead[LO]	{}											 %set header to left	
\renewcommand{\footrulewidth}{0.5pt}		% print horizontal line in the footer of 0.5 pt
\fancyfoot[RO]{\textit{Dept. of Information Technology}}		%set footer to right
\fancyfoot[LO]{\textit{PICT,Pune}}			%set footer to left
\fancypagestyle{plain}{}
\pagenumbering{arabic}	
\chapter{\centering{Introduction}}
\begin{normalsize}
			\noindent

%-------------------------------------------------------------------------------------------------------
%  Start writing from here.
%(short para about your area describing its place in the world of Technology)
\section{Introduction} 	
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
Randomized Controlled Trial (RCT) is a specific type of study design commonly used in medical research to evaluate the effectiveness of a treatment or intervention. In an RCT, participants are randomly assigned to different groups to compare the outcomes of those who receive the treatment or intervention with those who do not. Existing models based on artificial neural networks (ANNs) for sentence classification often do not incorporate the context in which sentences appear and classify sentences individually.
The scope of medical abstract segmentation for RCTs using NLP and neural networks encompasses a wide range of applications that contribute to the advancement of healthcare, medical research, and clinical decision-making. This field con- tinues to evolve, driven by the increasing volume of medical literature and the need for more efficient ways to extract valuable insights from this vast body of knowledge.
For a variety of Natural Language Processing (NLP) activities, such as information retrieval, information extraction, and text summarization, structuring the unstructured Randomized Controlled Trial (RCT) is helpful. One example is classifying sentences into Background, Objective, Methods, Results, and Conclusion. However, a large number of PubMed abstracts lack hierarchical organization. Only about 30\% of all PubMed abstracts, according to Ripple et al. (2014), include their structural information, which hinders effective knowledge discovery and information retrieval from those sizable biomedical bibliographic databases. Sentence classification for medical abstracts has been the subject of a lot of studies.
The aim of "Medical Abstract Segmentation" is to focus on classifying sentences in medical abstracts, and particularly in randomized controlled trials (RCTs), as they are commonly considered to be the best source of medical evidence.
\par
}	
\section{Motivation}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
With the unprecedented growth of biomedical publications, structured abstracts in bibliographic databases  like PubMed are essential for assisting researchers with information retrieval and knowledge synthesis.
The number of Biomedical articles continue to grow. As of February 25th, 2022, PubMed a popular bibliographic database that aids scholars in locating articles of interest has over 40,000,000 publicly accessible abstracts. Medical abstracts structural information, such as the Background, Objective, Methods, Results, and Conclusion subsections, is helpful for a variety of Natural Language Processing (NLP) applications, including text summarization, information extraction, and information retrieval. However, a large number of PubMed abstracts lack subsection organization. Franck notes that more than half of all PubMed abstracts include their structural information [1], which restricts the amount of material that can be efficiently retrieved and knowledge that can be discovered from those extensive biomedical bibliographic databases. Thus, it is beneficial to create automated techniques for categorizing statements in biomedical abstracts into different subsections
\par}	

\section{Objectives}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
To enable more precise and relevant retrieval of medical information from abstracts by breaking them down into smaller, semantically coherent segments.
To facilitate the extraction of critical information from abstracts, including study objectives, methods, results, and conclusions. 
To assist healthcare professionals in making informed clinical decisions by providing them with easily accessible and relevant information from medical abstracts.

}
\section {Scope}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
The scope of medical abstract segmentation of Randomized Controlled Trials (RCTs) using Natural Language Processing (NLP) is substantial and holds great promise in the realm of healthcare and medical research. NLP-powered abstract segmentation offers the potential to transform the way we access and utilize critical information from RCTs. By breaking down RCT abstracts into structured sections and applying NLP techniques, we can enhance information retrieval, facilitate systematic literature reviews, automate data extraction for meta-analyses, and categorize content for more efficient referencing. Moreover, NLP enables semantic analysis and knowledge discovery, promoting evidence-based medicine by automating the identification of relevant clinical information. This structured data can also integrate seamlessly into clinical decision support systems, offering real-time insights for healthcare providers. With the continual evolution of NLP, the scope of medical abstract segmentation will only expand, making this technology an invaluable asset in the pursuit of improved healthcare practices and medical research.
}


%-----------------------Literature Survey & Discussion (Literature Survey)----------------
\newpage 
\chapter{\centering{Literature Survey}}

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=13cm]{litsurv2changes_1.jpg} % Include your table as a PDF image
%   \label{Literature Survey}
%   \caption{Literature Survey}
% \end{figure}

{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
\section{Existing Methodologies}
In many branches of natural language processing, including sentiment analysis, question answering, and dialog management, short-text classification is a crucial problem.A comprehensive study has been done on text classification in the domain of medical research papers. Some of the most recent and prominent ones have been used for this literature survey. 

In [1] the dataset consists of approximately 200,000 abstracts of randomized controlled trials, totaling 2.3 million sentences. Each sentence of each abstract is labeled with its role in the abstract using one of the following classes: background, objective, method, result, or conclusion, and PubMed 200k RCT is a substantial dataset designed for sequential sentence classification, is introduced. It notably stands as one of the largest datasets of its kind known to date. The evaluation encompasses the performance assessment of various baseline models, providing a valuable reference for researchers to readily benchmark their algorithms without the necessity of creating their own foundational benchmarks.

[2] suggests a novel uniform deep learning architecture and multi-task learning approach for cross-domain sequential sentence classification in scientific texts. This paper introduces a comprehensive deep-learning architecture designed for sequential sentence classification, demonstrating remarkable advancements, particularly in full paper datasets, without the need for intricate feature engineering. The authors conduct a thorough investigation and comparison of transfer learning approaches, shedding light on the exceptional effectiveness of multi-task models applied across diverse datasets. Furthermore, this study places significant emphasis on the crucial notion of semantic relatedness between classes within varying dataset annotation schemes. It proposes a practical and robust method for identifying and establishing these semantic connections. Such an approach bears the promise of unlocking the potential for cross-discipline applications in the domain of sentence classification, with particular relevance to academic search engines and information retrieval systems.

Similarly [3] Adopted a deep learning neural network model and pretrained the network on PubMed non-RCT dataset. Transfer Learning with fine-tuning was done on the hand-labeled dataset they created from scratch. The PubMed-non-RCT corpus was converted into a three-class dataset, and their model was trained on it. They achieved 92.1\% accuracy on the PubMed-non-RCT dataset. The model was then evaluated on various CS corpora using different approaches: 'Locally-trained,' 'Pre-trained on PubMed,' and 'Fine-tuned'. Notably, 'Fine-tuned' transfer learning significantly improved the model, while 'Pre-trained on PubMed' performed worse than local training, indicating the dissimilarity between the CS and biomedical corpora. Despite such differences, transfer learning with fine-tuning still provided more than a 10\% accuracy boost, even with entirely dissimilar datasets. The paper introduces a method for automatic discourse classification in computer science abstracts, showing that transfer learning with fine-tuning yields impressive results, even with limited labeled data. The model effectively generalizes across CS sub-fields, despite variations in discourse classification due to presentation style differences.

In [4] The model is composed of four components: the word embedding layer, the sentence encoding layer, the context enriching layer, and the label sequence optimization layer. The sequence of embedding vectors is first processed by a bi-directional RNN (bi-RNN) or CNN layer. In this work, they introduced an ANN-based hierarchical sequential labeling network designed to classify sequentially appearing sentences in text. By incorporating contextual information from neighboring sentences through an LSTM layer, they observed a significant enhancement in prediction quality. Their model demonstrated a notable 2\%-3\% improvement over state-of-the-art results in two datasets focusing on sequential sentence classification within medical abstracts. This proposed model's potential for generalization to various problems related to sequential sentence classification, including paragraph-level sequential sentence categorization in full-text articles, presents promising opportunities for text mining and document retrieval.

In [5] The model consists of two novel components: supervised local attention and an auxiliary span-based classification task. The proposed model aims to capture the latent segment structure of the document by considering the coherent semantics of contiguous sentences. It utilizes dynamic local attention to explicitly capture the structural information. 

In [6] a Machine Learning approach that aims to classify sentences according to the PIBOSO scheme is presented. A discriminative set of features that do not rely on any external resources to achieve results is used. In this paper, they introduced a machine-learning approach for identifying scientific artifacts in biomedical abstracts within the context of Evidence-Based Medicine. Their approach utilized sentence classification following the PIBOSO scheme. Importantly, their approach did not rely on external resources for classification features. The results demonstrated a significant improvement over existing methods, achieving a micro-average F-score of 90.74\% and 87.21\% for structured and unstructured abstracts, respectively. This marks a substantial increase compared to prior approaches.

In [7] The algorithm implemented is based on the following four steps:  Medical concepts are extracted from free-text descriptions of an interview and examination, a new representation of identified concepts is derived using concept embedding, concept embeddings are transformed into visit embeddings and clustering is performed on visit embeddings. They used two of the most common: k-means and hierarchical clustering with Ward’s method for merging clusters.  These algorithms cover two different clustering approaches. The algorithms are memory and time-efficient, so no need to use more advanced methods. 

[8] and [9] propose a few-shot prompt learning-based approach to classify sentences in medical abstracts of randomized clinical trials (RCT) and observational studies (OS) to subsections of Introduction, Background, Methods, Results, and Conclusion. 5 manually designed templates in a combination of 4 BERT model variants were tested and compared to a previous Hierarchical Sequential Labeling Network architecture and traditional BERT-based sentence classification method. Four deep learning models, namely RNN, LSTM, GRU, and BLSTM are used. Data pre-processing steps are applied that include: text cleaning, tokenization, stemming, as well as lemmatization to remove and stop words. Their approach achieves state-of-the-art results on all three datasets, surpassing Jin and Szolovits (2018) and their BERT-based baselines. The performance gap between their baselines and their best model is more pronounced for smaller datasets (CSABSTRUCT, NICTA) and narrower for the larger dataset (PUBMED-RCT), underlining the significance of pretraining for smaller datasets. To delve into the advantages of their joint sentence encoding relative to the BERT+Transformer baseline, they qualitatively analyze examples from CSABSTRUCT. They discover that a significant portion of such examples require contextual information for accurate classification, emphasizing the need for context in certain instances. In [10] ULMFiT stands as a game-changer in NLP, it delivers remarkable error reductions of 18-24 percent across six text classification tasks. Its open-sourced pre-trained models and code empower the NLP community with powerful tools for diverse applications.
[10] discusses the impact of inductive transfer learning on computer vision (CV) and how it has influenced deep neural networks in CV. It mentions that features in deep neural networks transition from general to task-specific from the first to the last layer, and most work in CV focuses on transferring the first layers of the model .

\begin{table*}%h
\begin{adjustbox}{width=\textwidth, totalheight=\textheight, keepaspectratio}
\begin{tabular}{|p{6cm}|p{8cm}|p{8cm}|p{3cm}|}
\hline
Title &
  Methodologies &
  Inferences &
  Dataset \\ \hline
\begin{tabular}[c]{@{}l@{}}PubMed 200k RCT: a Dataset for \\ Sequential Sentence \\ Classification in Medical Abstracts\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Dataset is constructed upon MED-\\ LINE/PubMed Baseline Database. \\ Abstracts are selected based on the\\ two criteria: \\ i. It must be an RCT\\ ii. It must be structured\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• It is the largest such dataset \\    in the field of Medical \\    Research.\\ • It evaluated the performance on \\   several baseline models \\   based on this dataset.\\ • It achieved state of the art results \\   for Bi-ANN model with \\   F1 score of 91.6\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}PubMed \\ 200k RCT\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Cross-Domain Multi-Task \\ Learning for Sequential Sentence \\ Classification in Research Papers\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1. Proposed SciBERT-HSLN architecture.\\ 2. Utilized SciBERT for Word Embeddings.\\ 3. Two approaches are suggested here one \\ without Transfer Learning and one with \\     Transfer Learning.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• It achieved state of the art results for \\    PMD dataset with F1 score of 93.1\\ • F1 score of 86.8 for NIC dataset\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}PMD, NIC, \\ ART, DRI\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Segmenting Scientific Abstracts \\ into Discourse Categories: \\ A Deep Learning-Based Approach \\ for Sparse Labeled Data\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} Transfer Learning with Fine Tuning was \\ done on the hand labelled dataset \\ they created from scratch.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• It was able to achieve 75\% accuracy \\    with the classification of CS abstracts.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Hand Labelled \\ corpus of \\ structured \\ CS abstracts\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Hierarchical Neural Networks \\ for Sequential Sentence \\ Classification in Medical \\ Scientific Abstracts\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} Model is composed of four layers :\\     i.   Word Embedding layer\\     ii.  Sentence Encoding layer\\     iii. Context Enriching layer\\     iv.  Label Sequence Optimisation layer\end{tabular} &
  • F1 score for PubMed 20k dataset is 92.6 &
  PubMed 20k RCT \\ \hline
\begin{tabular}[c]{@{}l@{}}A Span-based Dynamic\\  Local Attention Model for \\ Sequential Sentence \\ Classification\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} Model consists of two novel components:\\       i. supervised local attention\\       ii. auxiliary span based classification\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• F1 score of 92.8 on PubMed 20k RCT \\ • F1 score of 86.8 on NICTA-PIBOSO\end{tabular} &
  PubMed 20k RCT \\ \hline
\begin{tabular}[c]{@{}l@{}}Identifying scientific artefacts \\ in biomedical literature: \\ the Evidence Based Medicine \\ use case\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}A machine learning approach that aims \\     to classify sentences according to\\     PIBOSO scheme is presented.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• CRF classifier achieves F1 score of 90.74 \\    and 87.21 respectively over structured \\    and unstructured abstracts.\end{tabular} &
  NICTA-PIBOSO \\ \hline
\begin{tabular}[c]{@{}l@{}}Towards More Generalizable and \\ Accurate Sentence \\ Classification in \\ Medical Abstracts with Less Data\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} Few shot prompt based learning approach to \\ classify sentences in medical \\ abstracts was discussed.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• The study showed that the HSLN model \\    required only 20\% of the training data to \\    achieve comparable F1 scores when \\    compared with the baseline model.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}PubMed 200/20k\\ PubMed 20k OS\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Interpretable segmentation \\ of medical free-text records \\ based on word\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} K-Means and Hierarchical Clustering with \\ Ward's method was used.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• The embeddings outperformed \\    Pennington \\    et al on medical term analogies despite a \\    smaller corpus size.\\ • Future work should explore the dynamic \\    relationship with identified clusters.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}The Polish corpus \\ of free text \\ clinical records\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Pretrained Language Models\\  for Sequential Sentence\\ Classification\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} Four Deep Learning Models\\ namely RNN, LSTM,\\     GRU and BLSTM are used.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• Accuracy: BLSTM gives the highest \\    accuracy of 82.18\%\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Kaggle Dataset \\ having insult \\ labelled \\ comments \\ was used.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Deep Learning Based \\Text Classification: \\ A Comprehensive Review\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} Survey of more than 150 DL models \\was carried,which are developed \\in the past six years and \\ have significantly improved \\     state of the art on various TC tasks\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• Several state of the art models were used\\    in this paper\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}SQuAD,\\ WikiQA,\\ DBpedia\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Universal Language Model Fine-\\ tuning for Text Classification.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\\  Proposed discriminative fine-tuning, slanted \\     triangular learning rates, and \\gradual unfreezing\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• Method suggested significantly \\    outperforms \\    the state-of-the-art  on six text \\    classification tasks, reducing the error  \\    by 18-24\% on the majority \\    of datasets.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}TREC-6\\ IMDb\\ Yelp-bi Yelp-full\\ DBpedia\\ AG\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}A Hierarchical Model with \\ Recurrent Convolutional \\ Neural Networks for \\ Sequential Sentence Classification\end{tabular} &
  \begin{tabular}[c]{@{}l@{}} A new approach called SR-RCNN to generate \\     sentence encoding which uses both Bi-RNN \\     and text CNN to capture contextual and \\ literal relevance information\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• The model performs best on all datasets, \\    promoting previous best published \\    results by 0.5\%, 0.5\%and 2.5\% \\    on the PubMed 20k, PubMed 200k \\    and NICTA-PIBOSO dataset\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}PubMed RCT,\\ NICTA-PIBOSO\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Sectioning of Biomedical \\Abstracts: \\ A Sequence of Sequence\\ Classification Task.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1. It uses BIOBERT based model, with a \\ moving window to contextualise \\ the abstracts.\\ 2. Proposed SSN-4 Model consisting of \\ following four layers:\\          i. word embedding layer\\          ii. sentence representation layer\\          iii. BLSTM layer\\          iv. CRF layer\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}• The model trained with the MDS \\    performs fairly well in \\    both MDS and RCT data sets\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}A new data set \\ called MDS \\ that is \\ considerably \\ bigger than \\ PubMed RCT\end{tabular} \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Literature Survey}
\end{table*}
\section{Research Gap Analysis}
We came across important research gaps that require special attention in our quest to create a model for sequential sentence classification. Among these gaps, one major finding was that deep learning has not yet been fully exploited for sequential sentence classification on full papers,which shows that for texts consisting of thousands of lines the classification remains difficult. Also structured abstracts in other domains such as computer science papers are uncommon and availability of labelled dataset are also sparse, this hinders the progress of the ongoing research for cross-domain sequential sentence classification.\par

Most existing models focus on classifying sentences into broad categories, such as methods, results, and conclusions. However, in the context of evidence-based medicine, fine-grained classification is essential. Subdividing categories into more specific labels (e.g., participant characteristics, interventions, primary outcomes) can enhance the utility of the models in clinical research.
Furthermore, RCT abstracts are published in multiple languages, and incorporating linguistic diversity is a pressing research gap.
To bridge the gap between research and practical applications, further investigation is required on how sequential sentence classification can be integrated into clinical decision support systems.
\par



}

%---------------------------Analysis & Discussion----------------
\newpage 
\chapter{\centering{Requirement Specification and Analysis}}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
% Mention the specific details about your domain and Seminar area.
% Point out only those things that are relevant.
% WRITE ABOUT THE FUNCTIONING OF THE WEBSITE \\
% This project aims to develop a web application that utilizes the MURIL BERT model for classifying comments as "Non Aggressive," "Covertly Aggressive," or "Overly Aggressive." 
\section{Problem Definition}
Implementing text segmentation techniques using Natural Language Processing on randomised control trial (RCT) abstracts.

\section{Scope}
The scope of sequential sentence classification in RCT medical abstracts is broad and pivotal in the domain of evidence-based medicine. It encompasses the development and application of natural language processing (NLP) techniques to automatically parse and categorize the textual content within these abstracts. This includes recognizing essential elements such as study objectives, methodology, patient populations, interventions, and outcomes. The scope also extends to the integration of machine learning models and the creation of specialized algorithms to enhance the precision and recall of classification. Ultimately, this approach has the potential to revolutionize the systematic review process, enabling faster and more accurate retrieval of pertinent information for healthcare practitioners, researchers, and policymakers, thereby fostering advancements in medical research and patient care.
\section{Objectives}
The primary objectives for sequential sentence classification in randomized controlled trial (RCT) medical abstracts are twofold: Firstly, to identify and categorize the key information contained within these abstracts, such as the study design, intervention, outcomes, and results. This enables healthcare professionals, researchers, and decision-makers to efficiently assess the relevance and significance of the trial. Secondly, this classification aids in data extraction and indexing, contributing to the development of systematic reviews and evidence-based medicine. By accurately classifying and structuring the information in RCT abstracts, the goal is to enhance information retrieval and facilitate evidence synthesis, ultimately improving healthcare decision-making and research in the medical field.
\section{Proposed Methodology}
\subsection{Type of classification}
Sentence classification is a common task in natural language processing (NLP) and can be categorized into various types, depending on the specific problem or goal. Here are some common types of sentence classification:

1.Text Classification: 
    \begin{itemize}[left=2cm]
        \item Sentiment Analysis
        \item Sequential Sentence Classification
        \item Topic Classification
    \end{itemize}

2.Language Understanding:
    \begin{itemize}[left=2cm]
        \item Named Entity Recognition
        \item Part-of-Speech (POS) Tagging
    \end{itemize}
    
3.Document Summarization:
    \begin{itemize}[left=2cm]
        \item Sentence Importance Ranking:
    \end{itemize}

4.Question Answering:
    \begin{itemize}[left=2cm]
        \item Question Type Classification
        \item Answer Type Classification
    \end{itemize}
\subsection{Data import and cleaning}
The dataset was cloned from the publicly available github repository of [1]. The cloned PubMed RCT dataset consisted of four different sub-datasets within it.The four datasets are as follows :

1.PubMed\textunderscore200K\textunderscore RCT

2.PubMed\textunderscore200K\textunderscore RCT\textunderscore numbers\textunderscore replaced\textunderscore with\textunderscore at\textunderscore sign

3.PubMed\textunderscore20K\textunderscore RCT

4.PubMed\textunderscore20K\textunderscore RCT\textunderscore numbers\textunderscore replaced\textunderscore with\textunderscore at\textunderscore sign

Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.

The role of each sentence is prefixed at the start of each line separated by a tab (\textbackslash t) and each sentence finishes with a new line (\textbackslash n).

Different abstracts are separated by abstract ID's (lines beginning with \#\#\#) and newlines (\textbackslash n).

Prior to feature extraction, pre-processing is applied to the text to clean it and retain only the terms that provide valuable information for sentence classification. The cleaning function performs the following actions on the corpus:

1. Converting the text to lowercase.

2. Removal of Stopwords.

3. Stemming and Lemmatization. 

4. Tokenisation

After these steps, the dataset will be ready for feature engineering. 
After these steps, the dataset will be ready for feature engineering. 
\subsection{Feature Engineering}
The data should be transformed into a format that the
model can comprehend after being cleaned and preprocessed.
Feature engineering is a crucial step in the process of sequential sentence classification, a task commonly encountered in natural language processing (NLP) and text analysis. Sequential sentence classification involves assigning one or more labels to each sentence in a sequence, such as in sentiment analysis, named entity recognition, or text categorization. Effective feature engineering can significantly improve the performance of machine learning models used for this purpose.
There are various key aspects of Feature Engineering in Sequential Sentence Classification : 
\begin{enumerate}
    \item Text Representation
    \item Preprocessing
    \item Tokenization
    \item Feature Extraction
    \item Sequence Encoding
    \item Domain-Specific Knowledge
    \item Model Selection
\end{enumerate}

\break
\break
The major drawback of the two previous feature extraction techniques is the loss of the
relationship between words and, as a consequence, the context of a document. To overcome this problem,  a third extraction technique[10]
Word Embedding: The idea is to assign to similar terms close vectors of a continuous
and multidimensional vector space in a way that makes it possible to calculate similarities
between words or sentences thanks to the distance between vectors, as well as to
generalise a sentence into similar sentences, since the vectors will be similar[10].
Now another problem with this is about the context. If the same word is used for different context the word embedding fail to caputre this. 
This is overcomed by BERT which provides contextualized feature vectors.
We are planning to use the PubMedBERT which is a pretrained model on medical abstracts and literature.This model achieves state-of-the-art performance on several biomedical NLP tasks, as shown on the Biomedical Language Understanding and Reasoning Benchmark.
\\


\newpage
\section{Project Requirements}


\subsection{Datasets}
The PubMed 20K RCT dataset was used in this study. The dataset is available at https://github.com/Franck- Dernoncourt/pubmed-rct.
The collection includes 2.3 million phrases from almost 200,000 abstracts of randomized controlled trials. Each abstract's sentences are assigned a class based on their role in the abstract, such as background, objective, method, result, or conclusion.


For the specified problem of medical abstract segmentation, PubMed dataset is publicly available. It consists of following five labels and the number of samples are as follows:

1. METHODS          59353

2. RESULTS          57953

3. CONCLUSIONS      27168

4. BACKGROUND       21727

5. OBJECTIVE        13839
% \subsection{Functional Requirements}

% \subsection{Non Functional Requirements}
\subsection{Hardware Requirements}
\begin{itemize}
    \item CPU : i5 7th Gen Intel Core Processor
    \item RAM : 8GB 
    \item GPU : NVIDIA GeForce GTX 1060 or higher 
    \item Storage : 512GB SSD/HDD
\end{itemize}


\subsection{Software Requirements}
\begin{itemize}
    \item Integrated Development Environment (Jupyter Notebook)
    \item Programming language (Python Interpreter)
    \item TensorFlow
    \item SciKit Learn

\end{itemize}

% \section{Project Plan}

% \subsection{Project Resources}
% \subsection{Module Split-up}
% \subsection{Functional Decomposition}
% \subsection{Project Team Role and Responsibilities}
% \subsection{Project Plan 3.0}
% \subsection{PERT Table}
% \subsection{PERT Diagram}
% %Start writing from here.
% Here explain basic architecture or framework you have studied during Seminar.
}


%---------------------------Proposed solution & its Design--------------
\newpage 
\chapter{\centering{System Analysis and Design}}
{\setlength{\baselineskip}{1.1\baselineskip}

%---------- Proposed Solution
%those who have done implementation can 
\section{System Architecture}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.

\begin{figure}[h]
  \centering
  \includegraphics[width=16cm,height=10cm]{Model Architecture.png}
  \caption{Model Architechture}
  \label{fig:architectural}
\end{figure}

 The Hierarchical Sequential Labeling Network (HSLN) serves as the foundation for our method, which we refer to as PubMedBERT-HSLN. We assess the method on RCT abstracts using PubMedBERT as word embeddings.This research aims to present an empirical investigation on transfer learning and propose a uniform solution, rather than to surpass state-of-the-art results. The levels of our PubMedBERT-HSLN architecture are as follows: \\
 \begin{enumerate}[label=\Roman*., itemsep=10pt]
    \item Word Embeddings:
          A series of tokens (t1,t2,...,tm) from the phrase si is the input, while a sequence of (PubMedBERT) word embeddings (s1,s2,...,sm) is the output.
    \item Sentence Encoding:
          A Bi-LSTM is used to convert the input (w1,w2,...,wm) into representations (h1,h2,...,hm) that are enhanced with contextual information from the phrase.
    \item Context Enrichment:
          Sentence vectors (e1,e2,...,en) are converted into (c1,c2,...,cn) using a Bi-LSTM.As a result, context from adjacent sentences enriches each sentence vector ci.
    \item Output Layer:
          A CRF layer predicts the labels which acts like a final output layer based on highest conditional joint probability.
    
\end{enumerate}
      


}
\section{Necessary UML Diagrams}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
\subsection{Use Case Diagram}

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm,height=12cm]{Use Case Diagram.png }
    \caption{Use Case Diagram}
    \label{UCD}
\end{figure}


\subsection{DFD}
\begin{figure}[H]
    \centering
    \includegraphics[width=16cm,height=8cm]{DFD Diagram.png}
    \caption{Data Flow Diagram}
    \label{Data flow diagram}
\end{figure}

% \subsection{Activity Diagram}
\subsection{Sequence Diagram}
\begin{figure}[h]
    \centering
    \includegraphics[width=15cm]{Sequence diagram.png}
    \caption{Sequence Diagram}
    \label{fig: sequence diagram}
\end{figure}


% \section{Algorithm and Methodologies}

}


%---------------------------Implementation ----------------
% \newpage 
% \chapter{\centering{Implementation}}
% {\setlength{\baselineskip}{1.1\baselineskip}
% %Start writing from here.
% \section{Stages of Implementation}
% \subsection{	Data Preprocessing}
% \subsection{Implementation of Modules}
% (Elaborate Implementation Issues/ Techniques/ Software Tools etc.)
% \section{Experimentation Setup }
% (Specification of experimentation scenarios, setting of hyper parameters)
% \par


% %------------Results--------------------
\newpage 
\chapter{\centering{Results}}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
%\section{Results of Experiments }
\section{Result Analysis }
There are various metrics to evaluate the performance of a Machine Learning (ML) or Deep Learning (DL) classifier, and the choice of metric depends on the specific problem and the priorities of the task. 

\begin{enumerate}

\item Accuracy: A popular metric called accuracy counts the percentage of examples in a dataset that are properly classified out of all the occurrences in the dataset. A model with high accuracy may accurately classify both positive and negative events. Unbalanced datasets, where one class greatly outnumbers the other, are not a good fit for it. It is calculated as:

Accuracy = (TP + TN) / (TP + TN + FP + FN)

\item Precision:  Precision, sometimes referred to as positive predictive value, gauges how well a model predicts the positive outcomes. It is the proportion of accurate positive forecasts to all positive forecasts. A high degree of precision indicates a high likelihood of accuracy when the model predicts a positive class. When false positives are expensive or unwanted, it is especially crucial. It is calculated as:

Precision = TP / (TP + FP)

\item Recall (Sensitivity): Recall quantifies a model's capacity to accurately detect every positive event. It is often referred to as true positive rate or sensitivity. It is the proportion of real positive cases to all true positive cases. High recall means that the model can successfully identify the majority of the positive occurrences in the dataset. When it is undesirable to miss a favorable occurrence, this is crucial. It is calculated as:

Recall = TP / (TP + FN)

\item F1 Score: The harmonic mean of recall and precision is the F1 score. It is helpful when you wish to take into account both false positives and false negatives and offers a balance between these two metrics. When there is an unequal class distribution or when both precision and recall need to be considered, the F1 score is especially important. It offers a solitary metric that strikes a balance between recall and precision. It is calculated as:

F1 Score = 2 * (Precision * Recall) / (Precision + Recall)

\item ROC-AUC (Receiver Operating Characteristic - Area Under the Curve): Binary classification model performance is evaluated using ROC and AUC measures. At various thresholds, they aid in visualizing the trade-off between the real positive rate and the false positive rate. The capacity of a model to distinguish between positive and negative classes at different threshold values is shown graphically by the ROC curve. The AUC is a scalar value that provides a single number representation of a classification model's overall performance. The area under the ROC curve is measured.

\item Statistical Significance Testing: In many domains, including science, business, and machine learning, it is an essential part of data analysis and hypothesis testing. It assists in determining the likelihood that observed variations or effects in data are genuine and not the result of chance.

\item Log Loss: A popular metric for assessing the effectiveness of classification models is log loss (also known as cross-entropy loss), particularly in situations involving probability estimation. By contrasting the anticipated probabilities of a model with the actual probabilities or binary outcomes, it measures how accurate the model's predictions are. :

Log Loss = -1/N * Σ [y_i * log($\pi$) + (1 - y_i) * log(1 - $\pi$)]

\end{enumerate}

The choice of metric should be based on the specific goals of project and the nature of the data and problem one is dealing with. It's common to use a combination of these metrics to get a more holistic understanding of the classifier's performance.

% (Detailed discussion on experimentation results and comparison with the State-of-the-art Algorithms)


\section{Testing}
\subsubsection{K-Fold Cross-Validation}
K-Fold Cross-Validation is a technique used to assess a model's performance, especially in situations where the dataset is limited. It helps in estimating how well a model will generalize to unseen data. The dataset is divided into K subsets (or "folds") of roughly equal size. The model is trained and validated K times, each time using a different fold as the validation set and the remaining K-1 folds for training. The results from each fold are averaged to provide a single estimation of the model's performance. It provides a more reliable estimate of a model's performance compared to a single train-test split. It helps in detecting overfitting by assessing how consistent the model's performance is across different data subsets. 
\subsubsection{Unit Testing}
Unit testing is a software testing methodology where individual units, such as functions, methods, or classes, are tested in isolation to verify their correctness and behavior and also involves the testing of individual components like data preprocessing functions, feature extraction methods, machine learning models, custom algorithms, and functions that calculate evaluation metrics, data validation, ethical and bias analysis, error handling, security, and performance. The aim of using this was to ensure reliable and efficient working of individual components of our Medical Abstract Segmentation.
\subsubsection{Integration Testing}
The goal of integration testing is to assess the interactions between various system components, including models, custom algorithms, data validation, ethical analysis, error management, security, and performance. Ensuring that these elements function as a cohesive unit to produce a dependable and efficient Medical Classification system is the aim.
\subsubsection{Cross-Dataset Testing}
Cross-Dataset Testing is used to evaluate our model's generalization capability by assessing its performance on a different dataset than the one used for training and validation. The model, trained on source dataset, is tested on a completely independent dataset. The goal is to determine if the model can make accurate predictions on new, unseen data that it wasn't exposed to during training. It provides a realistic assessment of a model's ability to generalize to real-world data. It helps uncover dataset-specific biases and assess the robustness of the model.
\subsubsection{Statistical Significance Testing}
Statistical Significance Testing is used to determine whether observed differences or effects in data are statistically significant, meaning they are unlikely to have occurred by random chance. It involves defining null and alternative hypotheses and conducting statistical tests (e.g., t-tests, ANOVA, chi-squared tests) to assess the likelihood that observed differences are real. The p-value is used to make a judgment about the null hypothesis. It provides a principled way to determine if differences or effects are meaningful or if they could be attributed to random variations. It helps in making data-driven decisions and assessing the reliability of results.


%----------Conclusion-----------------
\newpage 
\chapter{\centering{Conclusion and Future Scope}}
{\setlength{\baselineskip}{1.1\baselineskip}
%Start writing from here.
\section{Conclusion}
Our work here contributes to the ongoing efforts for implementation of a Natural Language Processing (NLP) model designed for the segmentation of text lines in medical research paper abstracts. In this paper we extensively carried out empirical study of various deep learning models and explored particularly the bio-medical domain. The proposed model can be regarded as an initial benchmark, marking the starting point of an ongoing effort to construct an enhanced model.
\section{Limitations of the Project}
This research work does not test out the compatibility of various deep learning models with the feature engineering techniques discussed for the problem.
\section{Future Scope}
 For future enhancements, the following considerations merit attention: Replacement of Universal Sentence Encoder (USE) with Biomed NLP-PubMed BERT-base-uncased-abstract : Biomed NLP-PubMed BERT-base-uncased-abstract presents a compelling alternative to USE in terms of performance and accuracy.

Text Preprocessing: The absence of text preprocessing in our proposed architecture was a deliberate choice, aimed at minimizing feature dependencies during model training, following a similar approach for the ”current line” feature. 

Nevertheless, to further enhance model performance, it is recommended to consider text preprocessing techniques, such as the removal of stop words, punctuation, special characters, and webpage links, conversion to lowercase, as well as the application of stemming and lemmatization. These strategies can contribute to more refined and accurate model predictions. 


}



%---------------------------References----------------
\newpage
\addcontentsline{toc}{chapter}{References}
\bibliographystyle{plain}
\begin{normalsize}
				{\setlength{\baselineskip}{1.1\baselineskip}
{
\begin{thebibliography}{9}

\bibitem{b1} Franck Dernoncourt and Ji Young Lee, "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts," 2017 In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 308–313, Taipei, Taiwan. Asian Federation of Natural Language Processing.
\bibitem{b2} A. Brack, A. Hoppe, P. Buschermohle and R. Ewerth, "Cross-Domain Multi-Task Learning for Sequential Sentence Classification in Research Papers," in 2022 ACM/IEEE Joint Conference on Digital Libraries (JCDL), Cologne, Germany, 2022 pp. 1-13.
\bibitem{b3} Soumya Banerjee, Debarshi Kumar Sanyal, Samiran Chattopadhyay, Plaban Kumar Bhowmick, and Partha Pratim Das. 2020. Segmenting Scientific Abstracts into Discourse Categories: A Deep Learning-Based Approach for Sparse Labeled Data. In Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020 (JCDL '20). Association for Computing Machinery, New York, NY, USA, 429–432. https://doi.org/10.1145/3383583.3398598
\bibitem{b4} Di Jin and Peter Szolovits,"Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts," 2018 In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3100–3109, Brussels, Belgium. Association for Computational Linguistics.

\bibitem{b5} Xichen Shang, Qianli Ma, Zhenxi Lin, Jiangyue Yan, and Zipeng Chen, "A Span-based Dynamic Local Attention Model for Sequential Sentence Classification," 2021 In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 198–203, Online. Association for Computational Linguistics.
\bibitem{b6} Hassanzadeh H, Groza T, Hunter J. Identifying scientific artefacts in biomedical literature: the Evidence Based Medicine use case. J Biomed Inform. 2014 Jun;49:159-70. doi: 10.1016/j.jbi.2014.02.006. Epub 2014 Feb 14. PMID: 24530879.
\bibitem{b7} Adam Gabriel Dobrakowski, Agnieszka Mykowiecka, Małgorzata Marciniak, Wojciech Jaworski, Przemysław Biecek, "Interpretable segmentation of medical free-text records based on word embeddings." in Journal of Intelligent Information Systems, 2021, 
https://doi.org/10.1007/s10844-021-00659-4.
\bibitem{b8} Yan Hu, Yong Chen, Hua Xu, "Towards More Generalizable and Accurate Sentence Classification in Medical Abstracts with Less Data" Springer (Journal of Healthcare Informatics Research), 2023. 
https://doi.org/10.1007/s41666-023-00141-6
\bibitem{b9} Arman Cohan, Iz Beltagy, Daniel King, Bhavana Dalvi, Daniel S. Weld. "Pretrained Language Models for Sequential Sentence Classification." Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (2019). https://doi.org/10.48550/arXiv.1909.04054
\bibitem{b10} Jeremy Howard, Sebastian Ruder, "Universal Language Model Fine-tuning for Text Classification.", Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML), ACL 2018.
https://doi.org/10.48550/arXiv.1801.06146
\bibitem{b11} Xuelian Deng, Yuqing Li, Jian Weng and Jilian Zhang. "Feature selection for text classification: A review." Multimed Tools Appl 78, 3797–3816 (2019).
https://doi.org/10.1007/s11042-018-6083-5
\bibitem{b12} Jason Wei, Kai Zou. "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks" EMNLP-IJCNLP 2019 short paper. https://doi.org/10.48550/arXiv.1901.11196
\bibitem{b13} Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, Jianfeng Gao. "Deep Learning Based Text Classification: A Comprehensive Review" Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML), 2021. 
https://doi.org/10.48550/arXiv.2004.03705


\end{thebibliography}
\par}
}

\newpage					%start a new page

\appendix
\addcontentsline{toc}{chapter}{Plagiarism Report}
\newpage					%start a new page

\appendix
\addcontentsline{toc}{chapter}{Base Paper}
% Required package

\includepdf{sample.pdf} 
%Include external pdf file here

\newpage					%start a new page
\appendix
\addcontentsline{toc}{chapter}{Review Sheets}
% Required package
\includepdf{sample.pdf} 
%Include external pdf file here
\newpage					%start a new page
\appendix
\addcontentsline{toc}{chapter}{Monthly Planning Sheet}
% Required package
\includepdf{sample.pdf} 
%Include external pdf file here
\newpage					%start a new page
\appendix
\addcontentsline{toc}{chapter}{Project Achievements}
% Required package
\includepdf{sample.pdf} 
%Include external pdf file here
\end{normalsize}
\end{document}
